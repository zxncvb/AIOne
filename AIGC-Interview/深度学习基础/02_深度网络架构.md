### 第4章 卷积神经网络（CNN）
- 4.1 卷积操作原理（卷积核、步幅、填充、感受野）
- 4.2 卷积层的设计（1×1卷积、深度可分离卷积、转置卷积）
- 4.3 池化层
- 4.4 经典CNN架构（LeNet、AlexNet、VGG、GoogLeNet、ResNet、DenseNet、EfficientNet）

### 第5章 循环神经网络（RNN）
- 5.1 RNN基础（结构、BPTT）
- 5.2 梯度消失与梯度爆炸
- 5.3 门控机制（LSTM、GRU）
- 5.4 双向RNN与深层RNN

### 第6章 注意力机制与Transformer
- 6.1 注意力机制基础（软/硬注意力、注意力权重）
- 6.2 Self-Attention（Q、K、V、缩放点积注意力）
- 6.3 多头注意力（Multi-Head Attention）
- 6.4 Transformer架构详解（Encoder-Decoder、位置编码、残差连接、FFN、Mask机制）
- 6.5 Transformer变体与优化（BERT、GPT、T5/BART、RoPE、KV Cache、GQA、Flash Attention）
- 6.6 Transformer的扩展能力（Scaling Law）

### 第7章 图神经网络（GNN）
- 7.1 图的基本概念（节点、边、邻接矩阵、度矩阵）
- 7.2 图神经网络基础（消息传递机制）
- 7.3 图卷积网络（GCN）
- 7.4 图注意力网络（GAT）
- 7.5 其他GNN变体（GraphSAGE、GIN）
