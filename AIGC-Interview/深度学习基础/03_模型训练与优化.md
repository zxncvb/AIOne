### 第8章 损失函数
- 8.1 分类任务损失函数（交叉熵、Focal Loss）
- 8.2 回归任务损失函数（MSE、MAE、Huber Loss）
- 8.3 其他任务损失函数（对比学习、IoU Loss、知识蒸馏）

### 第9章 正则化技术
- 9.1 参数正则化（L1、L2、Elastic Net）
- 9.2 Dropout及其变体
- 9.3 数据增强（Mixup、CutMix、Cutout、Mosaic、AutoAugment）
- 9.4 早停（Early Stopping）
- 9.5 其他正则化方法（标签平滑、对抗训练）

### 第10章 归一化技术
- 10.1 归一化的基本原理（内部协变量偏移）
- 10.2 Batch Normalization（BN）
- 10.3 Layer Normalization（LN、RMSNorm）
- 10.4 其他归一化方法（IN、GN、WN）

### 第11章 优化算法
- 11.1 梯度下降基础（BGD、SGD、MBGD）
- 11.2 动量方法（Momentum、Nesterov）
- 11.3 自适应学习率方法（AdaGrad、RMSprop、Adam、AdamW、AdaFactor）
- 11.4 二阶优化方法（牛顿法、K-FAC）
- 11.5 优化策略与技巧（学习率调度、梯度裁剪、参数初始化）

### 第12章 模型训练技巧
- 12.1 训练流程管理
- 12.2 超参数调优
- 12.3 梯度问题（消失/爆炸、残差连接、梯度检查点）
- 12.4 预训练与微调（灾难性遗忘、冻结层、跨领域微调）

### 第13章 模型评估与部署
- 13.1 分类任务评估指标（Accuracy、Precision、Recall、F1、ROC-AUC）
- 13.2 回归任务评估指标（MSE、RMSE、MAE、R²）
- 13.3 检测/分割任务评估指标（IoU、mAP、Dice系数）
- 13.4 NLP任务评估指标（BLEU、ROUGE、困惑度、BERTScore）
- 13.5 模型部署（ONNX、TensorRT、模型量化、剪枝、知识蒸馏、TorchScript）
